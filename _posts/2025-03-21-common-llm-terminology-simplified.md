---
title: "Common LLM Terminology Simplified"
layout: single
excerpt_separator: "<!--more-->"
categories:
  - blog
tags:
  - AI
  - LLM
  - Business
  - Terminology
date: 2025-03-21 10:00:00 EST
timezone: America/New_York
search: true
toc: true
---

The terminology around AI, especially Large Language Models (LLMs), is changing so quickly, I thought it'd be a good idea to make some simple definitions of common terms. Here’s a simple, quick guide to some of the most common terms.

<!--more-->

### LLM (Large Language Model)

An LLM is an AI that's read and learned vast amounts of text and can **predict what words come next in a sentence**. Think of it as the world's most advanced autocomplete tool—like the predictive text feature on your phone but infinitely smarter.

### Neural Network

This is the technology behind LLMs, a network of **artificial "neurons"** (inspired by the **human brain**). Each neuron performs simple calculations, and together, they handle complex tasks, like the individual cogs in an incredibly complex machine.

### Parameters

Parameters are essentially the **adjustable knobs or switches within a neural network** that the model tunes during training to learn from data. The **more parameters**, the smarter and **more capable** the model typically is.

### Temperature

Temperature in LLMs controls **how creative or predictable the model’s responses will be**. A low temperature (close to 0) makes the AI more conservative and precise, while a higher temperature (closer to 1 or more) produces more diverse, imaginative responses.

### Prompt

A prompt is simply **the input you provide to an AI** to guide its response. It's like asking a clear question or giving specific instructions to someone to get exactly what you need. <br>
When you use AI tools, the tool will likely add some additional context onto your prompt to guide the output. For example, when using an image generation tool, the tool will likely add something like, "Respond with a .png image file with 1024x1024px resolution" to each of your prompts.

### Tokens

Tokens are chunks of words or characters processed by an AI. They're like individual puzzle pieces the model assembles to form coherent sentences and paragraphs. **Longer prompts or responses require more tokens**.

### Fine-tuning

Fine-tuning means taking a general-purpose AI and **teaching it further on specific topics** or tasks with specialized data. Imagine hiring an employee with general skills and training them specifically for your business's unique needs.

### Hallucination

Hallucination occurs when an AI **confidently gives incorrect or nonsensical information**. Imagine asking a confident colleague for directions, only to later realize they had no idea and just guessed convincingly. Remember, **AI doesn't know if it's right or wrong!**

### Reinforcement Learning with Human Feedback (RLHF)

RLHF means humans guide the AI’s learning by rating its responses, teaching the AI to better match human expectations. It’s like training a new employee by giving **regular feedback on their work** to improve over time.

### Context Window

The context window is **how much recent conversation or instruction the model can "remember"** when generating responses. It’s similar to your working memory—there’s only so much you can keep track of at once before you have to reference notes or past conversations. Having a very large context window can help generate more useful responses at the cost of more more processing power.
